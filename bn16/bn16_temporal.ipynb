{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RaNzg2RIBQW"
   },
   "source": [
    "# BN16\n",
    "\n",
    "Playground for the bn16 dataset, different temporal encoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BopKXkQNk6sA"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "Jb-Ecdr_XtO5",
    "outputId": "938762dd-a27a-465a-efed-b14e4794371c"
   },
   "outputs": [],
   "source": [
    "#!TMPDIR=../../tmp pip install torch==1.7.* torch-summary numpy pandas matplotlib sparse ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNYQvuF-Gpd9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary\n",
    "import sparse\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "from ipywidgets import interact, interactive\n",
    "import ipywidgets\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJA4BUyknSxx"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i9UsNk_ZnV3k",
    "outputId": "6ef67640-7d84-423f-f860-baf457b5f553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# DEVICE = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(DEVICE)\n",
    "RND_SEED = 1\n",
    "BATCH_SIZE = 8\n",
    "N_STEPS = 12\n",
    "N_INDIVIDUALS = 2443\n",
    "\n",
    "torch.random.manual_seed(RND_SEED)\n",
    "torch.cuda.manual_seed(RND_SEED)\n",
    "\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.min_rows = None\n",
    "pd.options.display.width = 800\n",
    "np.set_printoptions(edgeitems=5)\n",
    "np.core.arrayprint._line_width = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3XLCnjnk8fP"
   },
   "source": [
    "# Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has dimensions $I \\times I \\times D \\times T$, with $I \\times I$ being the individuals interactions matrix, $D$ being the day of observation and $T$ being the time of the snapshot (48 times half an hour). The actual dimensions are $2443 \\times 2443 \\times 56 \\times 48$.\n",
    "\n",
    "That means that we have sequences of length $56 \\cdot 48 = 2688$ (in time). The life span of the individuals depends on their tasks and individual factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyYOUNSJvNWN"
   },
   "source": [
    "## File Chunking\n",
    "\n",
    "Transform into daily chunks with dimensions: time x I x I where time is 48x half an hour and I is the individual."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f7c2e08c2fdd41d1acc7ad877708b5f7",
      "cfe9a8d890474b61887f2ecb2997dccd",
      "86c07288905449cbb1240186b334eef5",
      "b765884f57ee47efb8d5bc1a3b387faa",
      "0156e8d0482540eca99e27edc2bdb261",
      "3b80aa0abeba41d7891f8f6597058091",
      "958dfc4dc9314ae9b63f5a40aa1d0abf",
      "589fa440f5934454b099db6e0aa8c850"
     ]
    },
    "colab_type": "code",
    "id": "Ybgc-OIDX77v",
    "outputId": "3ad65298-431f-4814-eaf9-583f04586311"
   },
   "source": [
    "data = sparse.load_npz('bn16_intraday.npz')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y_T3dOXgnbMq",
    "outputId": "de2a166d-ce15-4831-8bd1-2488ffcd639f"
   },
   "source": [
    "# split into days\n",
    "for i in range(data.shape[2]):\n",
    "    d = data[:,:,i].transpose((2,0,1)) # to time x N x N\n",
    "    sparse.save_npz('daily/{}.npz'.format(i), d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# free up ram\n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = sparse.load_npz('bn16_intraday.npz')\n",
    "# split into individuals\n",
    "for i in range(data.shape[0]):\n",
    "    d = data[i].transpose((0, 2, 1)).reshape((data.shape[0], data.shape[2] * data.shape[3])).transpose() # 2443x56x48 => 2688x2443\n",
    "    sparse.save_npz('individuals/{}.npz'.format(i), d)\n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_start_date = datetime.datetime(2016, 7, 23, 0, 0, 0, 0)\n",
    "hatching_start_date = datetime.datetime(2016, 7, 19, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_data = pd.read_csv('indices_bn16.csv').sort_values(by='bee_id')\n",
    "alive_data = pd.read_csv('alive_bn16.csv').sort_values(by='bee_id').reset_index(drop=True) # required or the data will be messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bee_id</th>\n",
       "      <th>date_emerged</th>\n",
       "      <th>days_alive</th>\n",
       "      <th>interaction_matrix_idx</th>\n",
       "      <th>born_in_step</th>\n",
       "      <th>dead_by_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-192</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-192</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>-192</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-192</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>-192</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>-192</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>-192</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>-192</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>3255</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>24</td>\n",
       "      <td>2433</td>\n",
       "      <td>1488</td>\n",
       "      <td>2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>3256</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>14</td>\n",
       "      <td>2434</td>\n",
       "      <td>1488</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>3257</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>8</td>\n",
       "      <td>2435</td>\n",
       "      <td>1488</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>3258</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>10</td>\n",
       "      <td>2436</td>\n",
       "      <td>1488</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>3259</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>26</td>\n",
       "      <td>2437</td>\n",
       "      <td>1488</td>\n",
       "      <td>2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>3260</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>25</td>\n",
       "      <td>2438</td>\n",
       "      <td>1488</td>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>3261</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>16</td>\n",
       "      <td>2439</td>\n",
       "      <td>1488</td>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>3262</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>14</td>\n",
       "      <td>2440</td>\n",
       "      <td>1488</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>3263</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>22</td>\n",
       "      <td>2441</td>\n",
       "      <td>1488</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>3264</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>4</td>\n",
       "      <td>2442</td>\n",
       "      <td>1488</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bee_id date_emerged  days_alive  interaction_matrix_idx  born_in_step  dead_by_step\n",
       "0          9   2016-07-19           5                       0          -192            48\n",
       "1         10   2016-07-19          16                       1          -192           576\n",
       "2         17   2016-07-19           4                       2          -192             0\n",
       "3         21   2016-07-19          35                       3          -192          1488\n",
       "4         22   2016-07-19          19                       4          -192           720\n",
       "5         37   2016-07-19          15                       5          -192           528\n",
       "6         38   2016-07-19           8                       6          -192           192\n",
       "7         40   2016-07-19          14                       7          -192           480\n",
       "8         43   2016-07-19          18                       8          -192           672\n",
       "9         44   2016-07-19          24                       9          -192           960\n",
       "...      ...          ...         ...                     ...           ...           ...\n",
       "2433    3255   2016-08-23          24                    2433          1488          2640\n",
       "2434    3256   2016-08-23          14                    2434          1488          2160\n",
       "2435    3257   2016-08-23           8                    2435          1488          1872\n",
       "2436    3258   2016-08-23          10                    2436          1488          1968\n",
       "2437    3259   2016-08-23          26                    2437          1488          2736\n",
       "2438    3260   2016-08-23          25                    2438          1488          2688\n",
       "2439    3261   2016-08-23          16                    2439          1488          2256\n",
       "2440    3262   2016-08-23          14                    2440          1488          2160\n",
       "2441    3263   2016-08-23          22                    2441          1488          2544\n",
       "2442    3264   2016-08-23           4                    2442          1488          1680\n",
       "\n",
       "[2443 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both\n",
    "combined_alive_data = alive_data\n",
    "combined_alive_data['interaction_matrix_idx'] = indices_data['interaction_matrix_idx']\n",
    "# now sort by matrix id for easy vector generation\n",
    "combined_alive_data = combined_alive_data.sort_values(by='interaction_matrix_idx')\n",
    "# date column type fix\n",
    "combined_alive_data['date_emerged'] = pd.to_datetime(combined_alive_data['date_emerged'])\n",
    "# let's translate the hatch day into a step where observation_start_date is step 0\n",
    "combined_alive_data['born_in_step'] = combined_alive_data['date_emerged'].map(lambda x: (x - observation_start_date).days * 48)\n",
    "combined_alive_data['dead_by_step'] = combined_alive_data.apply(lambda row: 48 * row['days_alive'] + row['born_in_step'], axis=1)\n",
    "# combined_alive_data = get_combined_alive_data(indices_data, alive_data, observation_start_date)\n",
    "combined_alive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data insights like age distribution take a look at the `insights` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bee_id_to_matrix_id(bee_id, index_data):\n",
    "    '''Translates the bee ID into the matrix ID.'''\n",
    "    return indices_data[indices_data['bee_id'] == bee_id]['interaction_matrix_idx'].item()\n",
    "\n",
    "def matrix_id_to_bee_id(matrix_id):\n",
    "    '''Translates the matrix ID into the bee ID.'''\n",
    "    return indices_data[indices_data['interaction_matrix_idx'] == matrix_id]['bee_id'].item()\n",
    "\n",
    "def get_aliveness_vector(step):\n",
    "    '''Returns a #individuals-long boolean vector of matrix-ID-indexed bee aliveness.'''\n",
    "    return (combined_alive_data['born_in_step'] <= step) & (step < combined_alive_data['dead_by_step'])\n",
    "\n",
    "def get_lifespan_for_row(row, step):\n",
    "    if ((step < row['born_in_step']) | (row['dead_by_step'] < step)): #iloc[0] if you pass in a df\n",
    "        return 0\n",
    "    return row['dead_by_step'] - step  #iloc[0] if you pass in a df    \n",
    "\n",
    "def get_lifespan_vector(step):\n",
    "    '''Returns a #individuals-long vector of matrix-ID-indexed remaining bee lifespans in steps (half an hour).'''\n",
    "    return combined_alive_data.apply(get_lifespan_for_row, axis=1, step=step)\n",
    "\n",
    "def get_lifespan_for_individual(midx):\n",
    "    '''Get the remaining steps to live for given individual matrix index.'''\n",
    "    # start at zero, not before\n",
    "    bis = max(combined_alive_data[combined_alive_data['interaction_matrix_idx'] == midx]['born_in_step'].item(), 0)\n",
    "    dis = combined_alive_data.iloc[midx]['dead_by_step']\n",
    "    # full range, 56 days à 48 steps\n",
    "    r = np.zeros(56 * 48) \n",
    "    # dead in 4 steps => 4,3,2,1 - clip to length\n",
    "    ins = np.arange(dis - bis)[::-1][:len(r) - bis] \n",
    "    r[bis:bis + len(ins)] = ins\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circadian Rhythmicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bee_id</th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>circadian_rhythmicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.025426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.022645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1519</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1527</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1529</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>0.009352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bee_id  age       date  circadian_rhythmicity\n",
       "0     960    7 2016-07-26               0.025426\n",
       "1    1126    7 2016-07-26               0.022645\n",
       "2    1519    6 2016-07-26               0.002309\n",
       "3    1527    7 2016-07-26               0.002183\n",
       "4    1529    7 2016-07-26               0.009352"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circadian_data = pd.read_csv(\n",
    "    'rhythmicity_bn16.csv',\n",
    "    dtype={'bee_id': np.int16, 'age': np.int8, 'date': str, 'circadian_rhythmicity': np.float64},\n",
    "    parse_dates=['date'],\n",
    "    date_parser = pd.to_datetime\n",
    ")\n",
    "circadian_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to expand the days into 48 copies, also, we don't know if there are gaps in the date so we should not rely on the date to be continous\n",
    "def circadian_vector_for_individual(bee_id, circadian, observation_start_date):\n",
    "    '''Get the vector of circadian rhythmicity per step for a bee.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bee_id : int\n",
    "        The ID of the bee.\n",
    "    circadian : pd.DataFrame\n",
    "        The data frame with the circadian rhythmicities.\n",
    "    observation_start_date: datetime\n",
    "        The datetime of observation start.\n",
    "    '''\n",
    "    v = np.zeros(56 * 48)\n",
    "    for row in circadian[circadian['bee_id'] == bee_id].itertuples():\n",
    "        ins_start = (row.date - observation_start_date).days * 48\n",
    "        v[ins_start:ins_start + 48] = np.repeat(row.circadian_rhythmicity, 48)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneDayDataSet(Dataset):\n",
    "    '''Holds one complete day of the network.'''\n",
    "    def __init__(self, day, transform=None):\n",
    "        self.data = sparse.load_npz('daily/{}.npz'.format(day))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        d = torch.from_numpy(self.data[idx].todense())\n",
    "        if self.transform:\n",
    "            d = self.transform(d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualDataSet(Dataset):\n",
    "    '''Holds the data for one individual.'''\n",
    "    def __init__(self, day, transform=None):\n",
    "        self.data = sparse.load_npz('individuals/{}.npz'.format(day))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        d = torch.from_numpy(self.data[idx].todense())\n",
    "        if self.transform:\n",
    "            d = self.transform(d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bn16DataSet(Dataset):\n",
    "    def __init__(self, days=(0, 56), transform=None):\n",
    "        self.days = days\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2443\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        d = sparse.load_npz('individuals/{}.npz'.format(idx))\n",
    "        d = d[self.days[0] * 48:self.days[1] * 48]\n",
    "        d = torch.from_numpy(d.todense().astype(np.float32))\n",
    "        if self.transform:\n",
    "            d = self.transform(d)\n",
    "        return (\n",
    "            d,\n",
    "            {\n",
    "                'lifespan': get_lifespan_for_individual(idx).astype('float'),\n",
    "                'circadian': circadian_vector_for_individual(\n",
    "                    matrix_id_to_bee_id(idx),\n",
    "                    circadian_data,\n",
    "                    observation_start_date\n",
    "                ).astype('float')\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2443"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 36 days\n",
    "bn16_data = Bn16DataSet(days=(0, 35))\n",
    "len(bn16_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 split\n",
    "train_data, test_data = random_split(bn16_data, [1955, 488])\n",
    "\n",
    "full_loader = DataLoader(\n",
    "    bn16_data\n",
    "    ,batch_size=BATCH_SIZE\n",
    "    ,shuffle=True\n",
    "    ,num_workers=4\n",
    "    ,drop_last=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_data\n",
    "    ,batch_size=BATCH_SIZE\n",
    "    ,shuffle=True\n",
    "    ,num_workers=4\n",
    "    ,drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data\n",
    "    ,batch_size=BATCH_SIZE\n",
    "    ,shuffle=True\n",
    "    ,num_workers=2\n",
    "    ,drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([8, 1680, 2443]) {'lifespan': tensor([[ 143.,  142.,  141.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        ...,\n",
      "        [1775., 1774., 1773.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.]], dtype=torch.float64), 'circadian': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1023, 0.1023, 0.1023],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(idx, x.shape, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 244, 61)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_loader), len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC(nn.Module):\n",
    "    def __init__(self, n_steps, batch_size, hidden_size=256, context_size=256):\n",
    "        super(CPC, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.hidden_size = hidden_size\n",
    "        self.context_size = context_size\n",
    "        self.g_enc = self.encoder()\n",
    "        self.g_ar = self.autoregressive()\n",
    "        self.step_W = nn.ModuleList([nn.Linear(self.context_size, self.hidden_size) for i in range(n_steps)])\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.cpc_target = torch.arange(0, batch_size).long().to(DEVICE)\n",
    "\n",
    "    def encoder(self):            \n",
    "        # conv2d signature: in, out, kernel, stride, padding\n",
    "        # input is: batch, channel, time, interactions\n",
    "        return nn.Sequential(\n",
    "            # temporal downsampling :\n",
    "#             nn.Conv2d(1, 32, (8, 1), (4, 1), (2, 0)), # 2 * 1680 / 8 = 420\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, self.hidden_size, (1, 2443), 1, 0),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "            # temporal downsampling : ~55% CPC\n",
    "            nn.Conv2d(1, 128, (8, 1), 4, (4, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, (4, 1), 2, (2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, self.hidden_size, (211, 1), 1, 0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def autoregressive(self):\n",
    "        return nn.GRU(self.hidden_size, self.context_size, batch_first=True)\n",
    "\n",
    "    def predict(self, x, hidden=None):\n",
    "        '''Return c_t for the whole given x, all its steps and the hidden state.'''\n",
    "        with torch.no_grad():\n",
    "            if hidden == None:\n",
    "                hidden = self.empty_hidden()\n",
    "            z = self.g_enc(x)\n",
    "            z = z.squeeze().permute(0, 2, 1)\n",
    "            pred, hidden = self.g_ar(z, hidden)\n",
    "            return pred[:,-1,:], pred, hidden\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x, gar_hidden):\n",
    "        # put through g_enc\n",
    "#         print(x.shape) # 8, 1680, 2443\n",
    "        z = self.g_enc(x) # for convs\n",
    "#         z = self.g_enc(x.squeeze()) # for others\n",
    "#         z = self.g_enc(x.permute((0,2,1)))\n",
    "#         z = self.g_enc(x.permute((2,0,1)), torch.zeros((x.shape[2], x.shape[0], self.hidden_size)))\n",
    "#         print(z.shape) # 8, 256, 1680, 1\n",
    "        # sample a subsequence of n steps\n",
    "        # but we need at least one bit to feed into the GRU, so we pick from 1 to seqlen - n_steps\n",
    "        subsample_idx = torch.randint(1, z.shape[1] - self.n_steps, size=(1,)) # 1-1680-12 = 1667\n",
    "        \n",
    "        # put everything before our pick through g_ar, collect c_t        \n",
    "        # g_ar expects shape(batch, seq_len, input_size), h_0 of shape (num_layers * num_directions, batch, hidden_size)\n",
    "        # https://pytorch.org/docs/master/generated/torch.nn.GRU.html#torch.nn.GRU\n",
    "        # https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/\n",
    "        z = z.squeeze().permute(0, 2, 1)\n",
    "        c_tx, gar_hidden = self.g_ar(z[:,:subsample_idx,:], gar_hidden)\n",
    "        c_t = c_tx[:,-1,:].squeeze() # GRU outputs a c for every step - we want the last\n",
    "        #print(c_tx.shape) # e.g. 8*112*256\n",
    "\n",
    "        # for n steps, put through W_k for corresponding step to get predictions\n",
    "        # W_k * c_t\n",
    "        pred = [self.step_W[step](c_t) for step in range(self.n_steps)]\n",
    "        #print(pred[0].shape) # 8*512\n",
    "\n",
    "        # info nce loss\n",
    "        acc = []\n",
    "        info_nce_loss = []\n",
    "        for time_step in range(self.n_steps):\n",
    "            # f_k = exp(z_{t+k} * W_k * c_t)\n",
    "            f_k = torch.mm(z[:,subsample_idx + time_step,:].squeeze(), torch.transpose(pred[time_step], 0, 1))\n",
    "            info_nce_loss.append(self.loss_criterion(f_k, self.cpc_target))\n",
    "            accuracy = torch.mean((torch.argmax(f_k, dim=1) == self.cpc_target).float())\n",
    "            acc.append(accuracy)\n",
    "        info_nce_loss = torch.stack(info_nce_loss).mean()\n",
    "        \n",
    "        return torch.mean(info_nce_loss), torch.mean(torch.tensor(acc))\n",
    "    \n",
    "    def empty_hidden(self):\n",
    "        return torch.zeros(1, self.batch_size, self.context_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_model = CPC(N_STEPS, BATCH_SIZE, hidden_size=64, context_size=128).to(DEVICE)\n",
    "# summary(view_model.g_enc, (1 , 1680, 2443))\n",
    "# print()\n",
    "# summary(view_model.g_ar, (1, 64))\n",
    "# del view_model\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, optimizer, data_loader):\n",
    "    model.train()\n",
    "    loss = 0 # epoch loss\n",
    "    acc = 0  # epoch acc\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    time_epoch_start = timer()\n",
    "    report_steps = [.25, .50, .75]\n",
    "    report_steps.reverse()\n",
    "    for batch_idx, (x, y) in enumerate(data_loader):\n",
    "        time_batch_start = timer()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        # add channel dimension - for convolutions\n",
    "        if len(x.shape) < 4:\n",
    "            x = x.unsqueeze(1).to(DEVICE)\n",
    "\n",
    "        # pad to multiple of num heads for transformer\n",
    "#         x = torch.cat((x, torch.zeros(x.shape[0], x.shape[1], 5)), dim=2).to(DEVICE)\n",
    "        \n",
    "        # fwd - info_nce loss inside forward\n",
    "        loss, accuracy = model(x, model.empty_hidden())\n",
    "        \n",
    "        # back\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        epoch_acc.append(accuracy)\n",
    "\n",
    "        # progress report every couple updates\n",
    "        #if batch_idx % 40 == 0:\n",
    "        if len(report_steps) > 0 and batch_idx / len(data_loader) > report_steps[-1]:\n",
    "            report_steps.pop()\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.8f}\\tAcc: {:.2f}%\\tTime: {:.6f}'.format(\n",
    "                    epoch,\n",
    "                    batch_idx * BATCH_SIZE,\n",
    "                    len(data_loader.dataset),\n",
    "                    100. * batch_idx / len(data_loader),\n",
    "                    loss,\n",
    "                    accuracy * 100,\n",
    "                    timer() - time_batch_start\n",
    "                ))\n",
    "\n",
    "    epoch_loss_mean = torch.mean(torch.tensor(epoch_loss, dtype=torch.float64)).item()\n",
    "    epoch_acc_mean = torch.mean(torch.tensor(epoch_acc, dtype=torch.float64)).item()\n",
    "    # epoch report\n",
    "    print('Epoch: {} [{}/{} (100%)]\\tEpoch Loss: {:.8f}\\tEpoch Acc: {:.2f}%\\tEpoch Time: {:.6f}'.format(\n",
    "        epoch,\n",
    "        len(data_loader.dataset),\n",
    "        len(data_loader.dataset),\n",
    "        epoch_loss_mean,\n",
    "        epoch_acc_mean * 100,\n",
    "        timer() - time_epoch_start\n",
    "    ))\n",
    "    return epoch_loss_mean, epoch_acc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://zenodo.org/record/3862966\n",
    "\n",
    "Downstream tasks are:\n",
    "\n",
    "1. Aliveness prediction\n",
    "2. Circadian rhythmicity\n",
    "3. Task allocation (via time spent on substrates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest downstream task should be the aliveness prediction. A boolean output answering the question whether an individual is alive or not given a history of interaction matrices might be too easy - if there's some interaction it must be alive, if there is none it might be dead. But predicting how long an individual still has to live is a harder task. Still, if there was no interaction in the recent past the prediction should be zero. But if there was, it's probably hard to predict the future. But how do we deal with the case that the individual was not yet born? Do we output zero? The aliveness ground truth is day-based but our observations are half-hourly. How do we encode this? The value should maybe gradually fade out to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aliveness Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlivenessEstimator(nn.Module):\n",
    "    '''Simple linear regression.'''\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(AlivenessEstimator, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.linear(x.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the estimator we will choose an index $0 < i <= len_{seq}$ and feed the sequences until this index. The estimator must then predict the remaining life time for the individuals from that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_y(y, step):\n",
    "    # step 1 has the first 6, then it adds 8\n",
    "    return y[:,6+4*step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(cpc_model, downstream_model, downstream_key, optimizer, loss_fn, epoch, data_loader, ctx_size):\n",
    "    cpc_model.to(DEVICE)\n",
    "    cpc_model.eval()\n",
    "    downstream_model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    #epoch_acc = []\n",
    "    epoch_mae = []\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # add channel dim\n",
    "        x = x.unsqueeze(1).to(DEVICE)\n",
    "        y = y[downstream_key]\n",
    "        y.to(DEVICE)\n",
    "        #print(x.shape) # 8,1,1680,2443\n",
    "#         print(y.shape)\n",
    "        \n",
    "        # cpc output\n",
    "        output, c, hidden = cpc_model.predict(x)\n",
    "        #c_t = output.contiguous().view((-1, 256))\n",
    "        #print(c.shape) # 8,840,256\n",
    "\n",
    "        # pick an index 0 < i <= len(seq) to feed to the model\n",
    "        # then diff the lifespan for that index against the prediction\n",
    "        # TODO: we could use more than one index per batch\n",
    "#         print('c.shape:', c.shape)\n",
    "        rand_seq_idx = torch.randint(low=1, high=c.shape[2], size=(1,))\n",
    "#         print('rand:\\t', rand_seq_idx.item())\n",
    "        c = c[:,rand_seq_idx].contiguous().view((-1, ctx_size)) # adjust to context size\n",
    "#         print('y.shape:', y.shape)\n",
    "#         print('y slice:', y[:,rand_seq_idx])\n",
    "#         y = y[:,rand_seq_idx]\n",
    "        y = get_temp_y(y, rand_seq_idx)\n",
    "        \n",
    "        # shuffle batch\n",
    "#         y = y.view((-1,1)) # to column\n",
    "#         shuffle_idx = torch.randperm(BATCH_SIZE) \n",
    "#         c_t = c_t[shuffle_idx,:]\n",
    "#         y = y[shuffle_idx,:].view((-1,)) # to row\n",
    "        \n",
    "        # classifier fwd\n",
    "#         c_t = c_t.to(DEVICE)\n",
    "        c_t = c.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        output = downstream_model(c_t)\n",
    "#         print(output)\n",
    "\n",
    "        #print(output.shape, output.max(1, keepdim=True)[1])\n",
    "\n",
    "        # loss & backprop\n",
    "        loss = loss_fn(output.double(), y.double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # metrics\n",
    "        epoch_loss.append(loss.item())\n",
    "        #epoch_acc.append(acc)\n",
    "        epoch_mae.append(F.l1_loss(output, y, reduction='mean').item())\n",
    "        \n",
    "        # intra epoch results\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tMAE: {:.2f}\\tMSE: {:.6f}'.format(\n",
    "                epoch, batch_idx * BATCH_SIZE, len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), epoch_mae[-1], loss.item()))\n",
    "        \n",
    "    return torch.mean(torch.tensor(epoch_loss)), torch.mean(torch.tensor(epoch_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circadian Rhythmicity\n",
    "\n",
    "The cirdcadian rhythmicity can roughly be described as \"wake-sleep cycle\" - or better - that cycle is a result of the rhythmicity. Wild et. al tried to fit the activity cycle of the individuals, measured by their velocities withn a timespan, to a sine curve per individual (two parameters: amplitude and phase drift, fixed period of 1/d). They reported the R² values of the fit per individual.\n",
    "\n",
    "We will try to predict the R² value per individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircadianEstimator(nn.Module):\n",
    "    '''Simple linear regression.'''\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(CircadianEstimator, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.linear(x.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading\n",
    "\n",
    "Code for saving & loading checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = './checkpoints/'\n",
    "CHECKPOINT_PATH_DOWNSTREAM = './checkpoints/ds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, loss_hist, metrics, checkpoint_path, device=DEVICE):\n",
    "    '''Save the a given model's parameters, optimizer, loss and metrics[] history.'''\n",
    "    # in case there are some tensors map everything to plain numbers\n",
    "    loss = list(map(lambda x: x.item() if isinstance(x, torch.Tensor) else x, loss_hist))\n",
    "    for i in range(len(metrics)):\n",
    "        metrics[i] = list(map(lambda x: x.item() if isinstance(x, torch.Tensor) else x, metrics[i]))\n",
    "    \n",
    "    # move to CPU for saving\n",
    "    model.cpu() \n",
    "    checkpoint = {\n",
    "        'params': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'metrics': metrics,\n",
    "        'schema_version': 1\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    # move back to target device\n",
    "    model.to(device)\n",
    "    \n",
    "def load_model(model, optimizer, checkpoint_path, device=DEVICE):\n",
    "    '''Load a model's parameters, optimizer, loss and metrics[] history.'''\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(checkpoint['params'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    loss = checkpoint['loss']\n",
    "    metrics = checkpoint['metrics']\n",
    "    try:\n",
    "        schema_version = checkpoint['schema_version']\n",
    "    except KeyError:\n",
    "        schema_version = 1\n",
    "    return {\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'loss': loss,\n",
    "        'metrics': metrics,\n",
    "        'schema_version': schema_version\n",
    "    }\n",
    "\n",
    "def list_models():\n",
    "    return glob.glob('./checkpoints/*'), glob.glob('./checkpoints/ds/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./checkpoints/cpc_checkpoint_nbh.pt',\n",
       "  './checkpoints/cpc_checkpoint_32_64_500epochs.pt',\n",
       "  './checkpoints/cpc_checkpoint_nbh_64_128.pt',\n",
       "  './checkpoints/cpc_checkpoint_wide_cnn.pt',\n",
       "  './checkpoints/cpc_checkpoint_cembed_b64_h64',\n",
       "  './checkpoints/cpc_checkpoint_32_64.pt',\n",
       "  './checkpoints/cpc_checkpoint_pos512.pt',\n",
       "  './checkpoints/cpc_checkpoint_spatio_temp.pt',\n",
       "  './checkpoints/cpc_checkpoint_temp_stacked.pt',\n",
       "  './checkpoints/ds',\n",
       "  './checkpoints/cpc_checkpoint_hyperopt',\n",
       "  './checkpoints/cpc_checkpoint_cembed',\n",
       "  './checkpoints/cpc_checkpoint_hyperopt_lstm.pt',\n",
       "  './checkpoints/cpc_checkpoint_spatio_temp_fw.pt'],\n",
       " ['./checkpoints/ds/ds_checkpoint_pos512.pt',\n",
       "  './checkpoints/ds/ds_checkpoint_alive_cembed',\n",
       "  './checkpoints/ds/ds_circadian_pos_64_128.pt',\n",
       "  './checkpoints/ds/ds_checkpoint.pt',\n",
       "  './checkpoints/ds/ds_checkpoint_circadian_cembedxl',\n",
       "  './checkpoints/ds/ds_checkpoint_alive_64_128.pt',\n",
       "  './checkpoints/ds/ds_circadian_pos512.pt',\n",
       "  './checkpoints/ds/ds_checkpoint_alive_temp_spat',\n",
       "  './checkpoints/ds/ds_checkpoint_alive_hyperopt.pt',\n",
       "  './checkpoints/ds/ds_checkpoint_alive_cembedxl',\n",
       "  './checkpoints/ds/ds_checkpoint_nbh.pt',\n",
       "  './checkpoints/ds/ds_checkpoint_circadian_cembed'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - CPC\n",
    "\n",
    "Actual training of the CPC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CPC(N_STEPS, BATCH_SIZE, hidden_size=32, context_size=64).to(DEVICE)\n",
    "model = CPC(N_STEPS, BATCH_SIZE, hidden_size=256, context_size=256).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cpc = []\n",
    "acc_cpc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 [616/2443 (25%)]\tLoss: 1.36805153\tAcc: 43.75%\tTime: 0.216338\n",
      "Epoch: 0 [1224/2443 (50%)]\tLoss: 1.32342672\tAcc: 53.12%\tTime: 0.221252\n",
      "Epoch: 0 [1832/2443 (75%)]\tLoss: 1.29462218\tAcc: 39.58%\tTime: 0.215600\n",
      "Epoch: 0 [2443/2443 (100%)]\tEpoch Loss: 1.44696328\tEpoch Acc: 39.84%\tEpoch Time: 72.650860\n",
      "Epoch: 1 [616/2443 (25%)]\tLoss: 1.27148485\tAcc: 44.79%\tTime: 0.219018\n",
      "Epoch: 1 [1224/2443 (50%)]\tLoss: 1.31967771\tAcc: 45.83%\tTime: 0.222596\n",
      "Epoch: 1 [1832/2443 (75%)]\tLoss: 1.84119582\tAcc: 20.83%\tTime: 0.220676\n",
      "Epoch: 1 [2443/2443 (100%)]\tEpoch Loss: 1.38242628\tEpoch Acc: 42.42%\tEpoch Time: 72.501645\n",
      "Epoch: 2 [616/2443 (25%)]\tLoss: 1.52914500\tAcc: 34.38%\tTime: 0.217920\n",
      "Epoch: 2 [1224/2443 (50%)]\tLoss: 1.30170488\tAcc: 48.96%\tTime: 0.219162\n",
      "Epoch: 2 [1832/2443 (75%)]\tLoss: 1.50027776\tAcc: 33.33%\tTime: 0.218356\n",
      "Epoch: 2 [2443/2443 (100%)]\tEpoch Loss: 1.36572262\tEpoch Acc: 43.65%\tEpoch Time: 72.862816\n",
      "Epoch: 3 [616/2443 (25%)]\tLoss: 1.91132200\tAcc: 27.08%\tTime: 0.218582\n",
      "Epoch: 3 [1224/2443 (50%)]\tLoss: 0.94791114\tAcc: 65.62%\tTime: 0.220354\n",
      "Epoch: 3 [1832/2443 (75%)]\tLoss: 1.52515161\tAcc: 41.67%\tTime: 0.220163\n",
      "Epoch: 3 [2443/2443 (100%)]\tEpoch Loss: 1.30674419\tEpoch Acc: 45.98%\tEpoch Time: 72.529866\n",
      "Epoch: 4 [616/2443 (25%)]\tLoss: 1.32202411\tAcc: 51.04%\tTime: 0.221615\n",
      "Epoch: 4 [1224/2443 (50%)]\tLoss: 1.41081607\tAcc: 52.08%\tTime: 0.222643\n",
      "Epoch: 4 [1832/2443 (75%)]\tLoss: 1.64886284\tAcc: 40.62%\tTime: 0.222273\n",
      "Epoch: 4 [2443/2443 (100%)]\tEpoch Loss: 1.28279458\tEpoch Acc: 46.79%\tEpoch Time: 72.960431\n",
      "Epoch: 5 [616/2443 (25%)]\tLoss: 0.75453919\tAcc: 69.79%\tTime: 0.221524\n",
      "Epoch: 5 [1224/2443 (50%)]\tLoss: 1.10147488\tAcc: 55.21%\tTime: 0.217356\n",
      "Epoch: 5 [1832/2443 (75%)]\tLoss: 0.79543281\tAcc: 60.42%\tTime: 0.221755\n",
      "Epoch: 5 [2443/2443 (100%)]\tEpoch Loss: 1.27309822\tEpoch Acc: 47.14%\tEpoch Time: 73.076116\n",
      "Epoch: 6 [616/2443 (25%)]\tLoss: 1.45040691\tAcc: 37.50%\tTime: 0.223396\n",
      "Epoch: 6 [1224/2443 (50%)]\tLoss: 0.91878289\tAcc: 59.38%\tTime: 0.221236\n",
      "Epoch: 6 [1832/2443 (75%)]\tLoss: 1.12979960\tAcc: 51.04%\tTime: 0.221476\n",
      "Epoch: 6 [2443/2443 (100%)]\tEpoch Loss: 1.22979940\tEpoch Acc: 49.00%\tEpoch Time: 73.119553\n",
      "Epoch: 7 [616/2443 (25%)]\tLoss: 1.54151249\tAcc: 38.54%\tTime: 0.217693\n",
      "Epoch: 7 [1224/2443 (50%)]\tLoss: 1.16186011\tAcc: 53.12%\tTime: 0.218165\n",
      "Epoch: 7 [1832/2443 (75%)]\tLoss: 1.15001535\tAcc: 50.00%\tTime: 0.220857\n",
      "Epoch: 7 [2443/2443 (100%)]\tEpoch Loss: 1.24493343\tEpoch Acc: 48.46%\tEpoch Time: 73.079223\n",
      "Epoch: 8 [616/2443 (25%)]\tLoss: 1.68726158\tAcc: 32.29%\tTime: 0.219004\n",
      "Epoch: 8 [1224/2443 (50%)]\tLoss: 1.24201477\tAcc: 46.88%\tTime: 0.221852\n",
      "Epoch: 8 [1832/2443 (75%)]\tLoss: 1.45933652\tAcc: 44.79%\tTime: 0.220510\n",
      "Epoch: 8 [2443/2443 (100%)]\tEpoch Loss: 1.24296776\tEpoch Acc: 48.37%\tEpoch Time: 73.073547\n",
      "Epoch: 9 [616/2443 (25%)]\tLoss: 1.03416562\tAcc: 61.46%\tTime: 0.223071\n",
      "Epoch: 9 [1224/2443 (50%)]\tLoss: 1.17720926\tAcc: 48.96%\tTime: 0.225609\n",
      "Epoch: 9 [1832/2443 (75%)]\tLoss: 1.47335052\tAcc: 40.62%\tTime: 0.218770\n",
      "Epoch: 9 [2443/2443 (100%)]\tEpoch Loss: 1.19863475\tEpoch Acc: 49.80%\tEpoch Time: 73.069410\n",
      "Epoch: 10 [616/2443 (25%)]\tLoss: 1.55984449\tAcc: 42.71%\tTime: 0.217624\n",
      "Epoch: 10 [1224/2443 (50%)]\tLoss: 1.50797653\tAcc: 41.67%\tTime: 0.215704\n",
      "Epoch: 10 [1832/2443 (75%)]\tLoss: 1.26685464\tAcc: 42.71%\tTime: 0.215433\n",
      "Epoch: 10 [2443/2443 (100%)]\tEpoch Loss: 1.17176706\tEpoch Acc: 51.45%\tEpoch Time: 73.144794\n",
      "Epoch: 11 [616/2443 (25%)]\tLoss: 0.99528980\tAcc: 67.71%\tTime: 0.222120\n",
      "Epoch: 11 [1224/2443 (50%)]\tLoss: 0.91628122\tAcc: 56.25%\tTime: 0.221940\n",
      "Epoch: 11 [1832/2443 (75%)]\tLoss: 1.67333913\tAcc: 30.21%\tTime: 0.215505\n",
      "Epoch: 11 [2443/2443 (100%)]\tEpoch Loss: 1.17634937\tEpoch Acc: 51.21%\tEpoch Time: 72.817284\n",
      "Epoch: 12 [616/2443 (25%)]\tLoss: 1.02021456\tAcc: 54.17%\tTime: 0.224517\n",
      "Epoch: 12 [1224/2443 (50%)]\tLoss: 1.27611864\tAcc: 51.04%\tTime: 0.221338\n",
      "Epoch: 12 [1832/2443 (75%)]\tLoss: 0.93257797\tAcc: 59.38%\tTime: 0.221986\n",
      "Epoch: 12 [2443/2443 (100%)]\tEpoch Loss: 1.16834243\tEpoch Acc: 51.58%\tEpoch Time: 72.458097\n",
      "Epoch: 13 [616/2443 (25%)]\tLoss: 0.68548650\tAcc: 72.92%\tTime: 0.219569\n",
      "Epoch: 13 [1224/2443 (50%)]\tLoss: 0.97766560\tAcc: 61.46%\tTime: 0.219927\n",
      "Epoch: 13 [1832/2443 (75%)]\tLoss: 1.38733315\tAcc: 44.79%\tTime: 0.218194\n",
      "Epoch: 13 [2443/2443 (100%)]\tEpoch Loss: 1.20081812\tEpoch Acc: 50.54%\tEpoch Time: 72.713326\n",
      "Epoch: 14 [616/2443 (25%)]\tLoss: 1.52994633\tAcc: 42.71%\tTime: 0.218421\n",
      "Epoch: 14 [1224/2443 (50%)]\tLoss: 0.73678315\tAcc: 67.71%\tTime: 0.219961\n",
      "Epoch: 14 [1832/2443 (75%)]\tLoss: 1.03312802\tAcc: 54.17%\tTime: 0.220372\n",
      "Epoch: 14 [2443/2443 (100%)]\tEpoch Loss: 1.17546966\tEpoch Acc: 51.29%\tEpoch Time: 72.378508\n",
      "Epoch: 15 [616/2443 (25%)]\tLoss: 1.60682750\tAcc: 36.46%\tTime: 0.218660\n",
      "Epoch: 15 [1224/2443 (50%)]\tLoss: 1.49287879\tAcc: 35.42%\tTime: 0.217749\n",
      "Epoch: 15 [1832/2443 (75%)]\tLoss: 1.09968507\tAcc: 47.92%\tTime: 0.221246\n",
      "Epoch: 15 [2443/2443 (100%)]\tEpoch Loss: 1.16279580\tEpoch Acc: 51.65%\tEpoch Time: 73.119360\n",
      "Epoch: 16 [616/2443 (25%)]\tLoss: 1.63484859\tAcc: 34.38%\tTime: 0.217978\n",
      "Epoch: 16 [1224/2443 (50%)]\tLoss: 1.05623519\tAcc: 54.17%\tTime: 0.220896\n",
      "Epoch: 16 [1832/2443 (75%)]\tLoss: 1.17542720\tAcc: 50.00%\tTime: 0.216434\n",
      "Epoch: 16 [2443/2443 (100%)]\tEpoch Loss: 1.14278433\tEpoch Acc: 52.54%\tEpoch Time: 72.391730\n",
      "Epoch: 17 [616/2443 (25%)]\tLoss: 0.96454537\tAcc: 57.29%\tTime: 0.222725\n",
      "Epoch: 17 [1224/2443 (50%)]\tLoss: 0.63542324\tAcc: 69.79%\tTime: 0.220191\n",
      "Epoch: 17 [1832/2443 (75%)]\tLoss: 1.33265448\tAcc: 43.75%\tTime: 0.216728\n",
      "Epoch: 17 [2443/2443 (100%)]\tEpoch Loss: 1.10805775\tEpoch Acc: 53.97%\tEpoch Time: 72.910715\n",
      "Epoch: 18 [616/2443 (25%)]\tLoss: 0.74440432\tAcc: 69.79%\tTime: 0.220322\n",
      "Epoch: 18 [1224/2443 (50%)]\tLoss: 0.97178531\tAcc: 56.25%\tTime: 0.223540\n",
      "Epoch: 18 [1832/2443 (75%)]\tLoss: 0.76656926\tAcc: 72.92%\tTime: 0.220823\n",
      "Epoch: 18 [2443/2443 (100%)]\tEpoch Loss: 1.11767304\tEpoch Acc: 53.48%\tEpoch Time: 72.624219\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(19):\n",
    "    l, a = train(model, epoch, optimizer, full_loader) # train_loader\n",
    "    loss_cpc.append(l)\n",
    "    acc_cpc.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0398449411157702, 0.5635587431856843)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax1.plot(np.arange(len(loss_cpc)), loss_cpc)\n",
    "ax1.set_xlabel('Epochs', fontsize=15)\n",
    "ax1.set_ylabel('Loss', fontsize=15)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.plot(np.arange(len(acc_cpc)), acc_cpc)\n",
    "ax2.set_xlabel('Epochs', fontsize=15)\n",
    "ax2.set_ylabel('Accuracy', fontsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "#fig.suptitle('CPC training metrics', fontsize=16)\n",
    "loss_cpc[-1], acc_cpc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, optimizer, loss_cpc, [acc_cpc], CHECKPOINT_PATH + 'cpc_checkpoint_temp_stacked.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False: # faster than commenting out - switch to True to load\n",
    "if True:\n",
    "    loaded_state = load_model(model, optimizer, CHECKPOINT_PATH + 'cpc_checkpoint_temp.pt')\n",
    "    loss_cpc = loaded_state['loss']\n",
    "    acc_cpc = loaded_state['metrics'][0]\n",
    "    del loaded_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Downstream\n",
    "\n",
    "Actual training of the downstream model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_model = AlivenessEstimator(256, 1).to(DEVICE)\n",
    "downstream_optimizer = torch.optim.Adam(downstream_model.parameters())\n",
    "downstream_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist_downstream = []\n",
    "second_metric_hist_downstream = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2b1abd0b5adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownstream_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lifespan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownstream_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownstream_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss_hist_downstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msecond_metric_hist_downstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-203da6befd00>\u001b[0m in \u001b[0;36mtrain_estimator\u001b[0;34m(cpc_model, downstream_model, downstream_key, optimizer, loss_fn, epoch, data_loader, ctx_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownstream_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;31m#         print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37bn16/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-af70f733055f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37bn16/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37bn16/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37bn16/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    l, a = train_estimator(model, downstream_model, 'lifespan', downstream_optimizer, downstream_loss, epoch, train_loader, 128)\n",
    "    loss_hist_downstream.append(l)\n",
    "    second_metric_hist_downstream.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax1.plot(np.arange(len(loss_hist_downstream)), loss_hist_downstream, linewidth=2)\n",
    "ax1.set_xlabel('Epochs', fontsize=15)\n",
    "ax1.set_ylabel('MSE Loss in $1 \\cdot 10^5$', fontsize=15)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,0), useOffset=True, useMathText=True)\n",
    "ax2.plot(np.arange(len(second_metric_hist_downstream)), second_metric_hist_downstream, linewidth=2)\n",
    "ax2.set_xlabel('Epochs', fontsize=15)\n",
    "ax2.set_ylabel('MAE Loss', fontsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "#fig.suptitle('Aliveness estimation training metrics', fontsize=16)\n",
    "plt.show()\n",
    "loss_hist_downstream[-1], second_metric_hist_downstream[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(downstream_model, downstream_optimizer, loss_hist_downstream, [second_metric_hist_downstream], CHECKPOINT_PATH_DOWNSTREAM + 'ds_checkpoint_alive_temp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # faster than commenting out - switch to True to load\n",
    "# if True:\n",
    "    loaded_state = load_model(downstream_model, downstream_optimizer, CHECKPOINT_PATH_DOWNSTREAM + 'ds_checkpoint_alive_64_128.pt')\n",
    "    loss_hist_downstream = loaded_state['loss']\n",
    "    second_metric_hist_downstream = loaded_state['metrics'][0]\n",
    "    del loaded_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circadian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_model = CircadianEstimator(64, 1).to(DEVICE)\n",
    "downstream_optimizer = torch.optim.Adam(downstream_model.parameters())\n",
    "downstream_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist_downstream = []\n",
    "second_metric_hist_downstream = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    l, a = train_estimator(model, downstream_model, 'circadian', downstream_optimizer, downstream_loss, epoch, train_loader, 64)\n",
    "    loss_hist_downstream.append(l)\n",
    "    second_metric_hist_downstream.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax1.plot(np.arange(len(loss_hist_downstream)), loss_hist_downstream)\n",
    "ax1.set_xlabel('Epochs', fontsize=15)\n",
    "ax1.set_ylabel('MSE Loss', fontsize=15)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax2.plot(np.arange(len(second_metric_hist_downstream)), second_metric_hist_downstream)\n",
    "ax2.set_xlabel('Epochs', fontsize=15)\n",
    "ax2.set_ylabel('MAE Loss', fontsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "#fig.suptitle('Circadian estimation training metrics', fontsize=16)\n",
    "loss_hist_downstream[-1], second_metric_hist_downstream[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(downstream_model, downstream_optimizer, loss_hist_downstream, [second_metric_hist_downstream], CHECKPOINT_PATH_DOWNSTREAM + 'ds_circadian_pos_64_128.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # faster than commenting out - switch to True to load\n",
    "# if True:\n",
    "    loaded_state = load_model(downstream_model, downstream_optimizer, CHECKPOINT_PATH_DOWNSTREAM + 'ds_circadian_pos_64_128.pt')\n",
    "    loss_hist_downstream = loaded_state['loss']\n",
    "    second_metric_hist_downstream = loaded_state['metrics'][0]\n",
    "    del loaded_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "A full evaluation would calculate the MSE for each time step for each individual. For now, we'll do a quick eval for some fixed steps.\n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2} = 1 - \\frac{\\sum{y - \\hat{y}}^2}{\\sum{y^2} - \\frac{1}{n} \\cdot (\\sum{y})^2}$\n",
    "(Steiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(cpc_model, downstream_model, downstream_key, data_loader):\n",
    "    cpc_model.to(DEVICE)\n",
    "    cpc_model.eval()\n",
    "    downstream_model.to(DEVICE)\n",
    "    downstream_model.eval()\n",
    "\n",
    "    downstream_mse = []\n",
    "    downstream_mae = []\n",
    "\n",
    "    time_steps_to_check = range(420)\n",
    "    \n",
    "    # for R²\n",
    "    n = 420 * BATCH_SIZE * len(data_loader) # 35 days á 48 steps x samples per batch x num batches\n",
    "    sum_of_errors = 0\n",
    "    y_sum = 0\n",
    "    y_sq_sum = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(data_loader):\n",
    "        # add channel dim\n",
    "        x = x.unsqueeze(1).to(DEVICE)\n",
    "        y = y[downstream_key].to(DEVICE)\n",
    "        \n",
    "        inner_mse = []\n",
    "        inner_mae = []\n",
    "\n",
    "        # cpc output\n",
    "        output, c, hidden = cpc_model.predict(x)\n",
    "        \n",
    "#         if len(time_steps_to_check) == 1:\n",
    "#             time_steps_to_check += [int(c.shape[1] / x) for x in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]]\n",
    "\n",
    "        for step in time_steps_to_check:\n",
    "            c_t = c[:,step].contiguous().view((-1, 128)).to(DEVICE)\n",
    "            #y_t = y[:,step].to(DEVICE)\n",
    "            y_t = get_temp_y(y, step).to(DEVICE)\n",
    "                \n",
    "            # classifier fwd\n",
    "            output = downstream_model.predict(c_t).squeeze()\n",
    "            \n",
    "            inner_mse.append(F.mse_loss(output, y_t, reduction='mean'))\n",
    "            inner_mae.append(F.l1_loss(output, y_t, reduction='mean'))\n",
    "            # for R²\n",
    "            sum_of_errors += torch.sum(torch.pow(y_t - output, 2)).item()\n",
    "            y_sum += torch.sum(y_t).item()\n",
    "            y_sq_sum += torch.sum(torch.pow(y_t, 2)).item()\n",
    "\n",
    "        downstream_mse.append(torch.mean(torch.tensor(inner_mse, dtype=torch.float64)))\n",
    "        downstream_mae.append(torch.mean(torch.tensor(inner_mae, dtype=torch.float64)))\n",
    "\n",
    "    # MSE, MAE, R²\n",
    "    return (\n",
    "        torch.mean(torch.tensor(downstream_mse, dtype=torch.float64)).item(), \n",
    "        torch.mean(torch.tensor(downstream_mae, dtype=torch.float64)).item(),\n",
    "        1 - sum_of_errors / (y_sq_sum - (y_sum ** 2) / n)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, downstream_model, 'lifespan', test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, downstream_model, 'circadian', test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean life time of an individual is 18 steps. Let's compare our validation to this baseline as well as to always predicting zero to get a feeling if our prediction is any good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_baselines(data_loader, downstream_key):\n",
    "    baseline_mse_0 = []\n",
    "    baseline_mae_0 = []\n",
    "    baseline_mse_mean = []\n",
    "    baseline_mae_mean = []\n",
    "    \n",
    "    baseline_0 = torch.zeros([8])\n",
    "    baseline_mean = torch.as_tensor(np.array([18 * 2] * 8))\n",
    "\n",
    "    #time_steps_to_check = [1] + [int(1680 / x) for x in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]]\n",
    "    time_steps_to_check = range(1680)\n",
    "    \n",
    "    # for R²\n",
    "    n = 1680 * BATCH_SIZE * len(data_loader) # 35 days á 48 steps x samples per batch x num batches\n",
    "    sum_of_errors = 0\n",
    "    y_sum = 0\n",
    "    y_sq_sum = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(data_loader):\n",
    "        y = y[downstream_key]\n",
    "        \n",
    "        inner_mse_0 = []\n",
    "        inner_mae_0 = []\n",
    "        inner_mse_mean = []\n",
    "        inner_mae_mean = []\n",
    "        \n",
    "        for step in time_steps_to_check:\n",
    "            y_t = y[:,step]\n",
    "            inner_mse_0.append(F.mse_loss(baseline_0, y_t, reduction='mean'))\n",
    "            inner_mae_0.append(F.l1_loss(baseline_0, y_t, reduction='mean'))\n",
    "            inner_mse_mean.append(F.mse_loss(baseline_mean, y_t, reduction='mean'))\n",
    "            inner_mae_mean.append(F.l1_loss(baseline_mean, y_t, reduction='mean'))\n",
    "            # for R²\n",
    "            sum_of_errors += torch.sum(torch.pow(y_t, 2)).item()\n",
    "            y_sum += torch.sum(y_t).item()\n",
    "            y_sq_sum += torch.sum(torch.pow(y_t, 2)).item()\n",
    "\n",
    "        baseline_mse_0.append(torch.mean(torch.tensor(inner_mse_0, dtype=torch.float64)))\n",
    "        baseline_mae_0.append(torch.mean(torch.tensor(inner_mae_0, dtype=torch.float64)))\n",
    "        baseline_mse_mean.append(torch.mean(torch.tensor(inner_mse_mean, dtype=torch.float64)))\n",
    "        baseline_mae_mean.append(torch.mean(torch.tensor(inner_mae_mean, dtype=torch.float64)))\n",
    "\n",
    "    print (\n",
    "        torch.mean(torch.tensor(baseline_mse_0, dtype=torch.float64)).item(),\n",
    "        torch.mean(torch.tensor(baseline_mae_0, dtype=torch.float64)).item(),\n",
    "        torch.mean(torch.tensor(baseline_mse_mean, dtype=torch.float64)).item(),\n",
    "        torch.mean(torch.tensor(baseline_mae_mean, dtype=torch.float64)).item(),\n",
    "        1 - sum_of_errors / (y_sq_sum - (y_sum ** 2) / n)\n",
    "    )\n",
    "    return baseline_mae_0, baseline_mae_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_0, mae_mean = val_baselines(test_loader, 'circadian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mae_0).plot()\n",
    "pd.DataFrame(mae_mean).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs\n",
    "\n",
    "What did our CNN learn? How do the weights look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CPC(N_STEPS, BATCH_SIZE, hidden_size=64, context_size=128)\n",
    "# load_model(model, optimizer, CHECKPOINT_PATH + 'cpc_checkpoint_nbh_64_128.pt')\n",
    "model.to('cpu')\n",
    "cnn_params = model.g_enc[0].weight.data\n",
    "\n",
    "print(cnn_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(cnn_params[0].squeeze().numpy()).plot(figsize=(14,4), legend=False)\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(18, 8))\n",
    "ax1.matshow(cnn_params[0].squeeze())\n",
    "ax2.matshow(cnn_params[1].squeeze())\n",
    "ax3.matshow(cnn_params[2].squeeze())\n",
    "ax4.matshow(cnn_params[3].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 8, figsize=(20, 20))\n",
    "for a in range(8):\n",
    "    for b in range(8):\n",
    "        ax[a][b].matshow(cnn_params[a * 8 + b].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(32, 1, figsize=(18, 10))\n",
    "vmin = cnn_params.min().item()\n",
    "vmax = cnn_params.max().item()\n",
    "for i in range(len(axes)):\n",
    "    im = axes[i].imshow(cnn_params.squeeze().numpy()[i:i+1], cmap='hot', interpolation='nearest', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    axes[i].tick_params(labelcolor='none', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "axes[-1].tick_params(axis='both', bottom=True, labelbottom=True, labelcolor='black')\n",
    "axes[-1].set_xlabel('Filter weights for individual', fontsize=25)\n",
    "axes[16].set_ylabel('Filter', fontsize=25)\n",
    "axes[-1].tick_params(axis='x', which='major', labelsize=15)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "# fig.suptitle('CNN kernel weights heatmap', fontsize=24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, figsize=(18, 18))\n",
    "vmin = cnn_params.min().item()\n",
    "vmax = cnn_params.max().item()\n",
    "for i in range(len(axes)):\n",
    "    im = axes[i].imshow(cnn_params.squeeze().numpy()[i:i+1], cmap='hot', interpolation='nearest', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    axes[i].tick_params(labelcolor='none', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "axes[-1].tick_params(axis='both', bottom=True, labelbottom=True, labelcolor='black')\n",
    "axes[-1].set_xlabel('Filter weights for individual', fontsize=25)\n",
    "axes[len(axes) // 2].set_ylabel('Filter', fontsize=25)\n",
    "axes[-1].tick_params(axis='x', which='major', labelsize=16)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "# fig.suptitle('CNN kernel weights heatmap for kernels 1-10', fontsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_params.squeeze().numpy()[0:1,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 1))\n",
    "im = ax.imshow(cnn_params.squeeze().numpy()[0:1,:10], cmap='hot', interpolation='nearest', aspect='equal')\n",
    "ax.tick_params(labelcolor='none', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "ax.set_xlabel('Filter weights for individual', fontsize=16)\n",
    "fig.colorbar(im)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_summary(DEVICE)\n",
    "int(torch.cuda.memory_allocated(DEVICE) / 1000 / 1000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CPC Librispeech.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0156e8d0482540eca99e27edc2bdb261": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b80aa0abeba41d7891f8f6597058091": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "589fa440f5934454b099db6e0aa8c850": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86c07288905449cbb1240186b334eef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b80aa0abeba41d7891f8f6597058091",
      "max": 6387309499,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0156e8d0482540eca99e27edc2bdb261",
      "value": 6387309499
     }
    },
    "958dfc4dc9314ae9b63f5a40aa1d0abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b765884f57ee47efb8d5bc1a3b387faa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589fa440f5934454b099db6e0aa8c850",
      "placeholder": "​",
      "style": "IPY_MODEL_958dfc4dc9314ae9b63f5a40aa1d0abf",
      "value": " 5.95G/5.95G [05:26&lt;00:00, 19.5MB/s]"
     }
    },
    "cfe9a8d890474b61887f2ecb2997dccd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7c2e08c2fdd41d1acc7ad877708b5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86c07288905449cbb1240186b334eef5",
       "IPY_MODEL_b765884f57ee47efb8d5bc1a3b387faa"
      ],
      "layout": "IPY_MODEL_cfe9a8d890474b61887f2ecb2997dccd"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
